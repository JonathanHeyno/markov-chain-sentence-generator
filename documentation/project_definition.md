# Markov chain sentence generator
The goal of the project is to create a program that can generate sentences based on an input of text, e.g. one or more books, poems, articles, musical lyrics, etc. Presumably the program will generate sentences in a similar style to the given input text.

## Algorithm design
Sentences are generated by drawing words according to probabilities based on previous ones through Markov chains. The probabilities of subsequent words following a given word, word couple, triple, etc. are stored in a trie structure. The trie structure has a worst-case time complexity of O(n) where n is the length of the longest word (or word pair, triple, etc.) in the input text. The space complexity is

O(N * (A^M))
where:
A = average amount of words following each word
M = order of the Markov chain
N = number of unique words in the source text


Special characters and numbers may cause problems in the implementation so they will be excluded.

We go through the source text and store into the trie each word, and the following N words, where N corresponds to the order of the Markov chain. We store to the last node in the word list the amount of times that specific wordlist has occurred in the source text. Based on this we can form the probabilities for a given word (or words) to follow a specific list of words. These probabilities are used to get the next word to be generated, which in turn will become the last word in the new list of words for which the next word is chosen, and so on.

The idea is presented below. In this example the source text contains the text '... cats eat alone if...'. For a second order Markov chain we store three word long lists into the trie, and the amount of times these three-word phrases are in the source text. So here we would have the phrase 'cats eat alone' present two times in the source text, and the phrase 'eat alone if' present four times.

Once the trie is constructed, we then count the probabilities from the frequencies, and use them to generate text. In this example, if we have the words 'cats eat', we then select the next word ('when', 'alone', 'after') according to their relative probabilities. The probability that the word 'alone' gets selected next is 2 / (3+2+6). If it gets selected, the next word pair is 'eat alone' and we select the next word the same way, and so on.

![trie_structure](./pics/trie_structure.svg)

## Input and output
The input is a text file with the text on which the sentence generation will be done, e.g. some book as a text file. The output will be text generated by following the Markov chain.

## Other information
- The project will be done with Python
- I can also evaluate a project done with Java
- Documentation will be in English
- Study program: Tietojenk√§sittelytieteen kandidaatti (TKT)


## Sources
- Trie structures:
	- [https://www.geeksforgeeks.org/trie-insert-and-search/](https://www.geeksforgeeks.org/trie-insert-and-search/)
	- [https://iq.opengenus.org/time-complexity-of-trie/](https://iq.opengenus.org/time-complexity-of-trie/)
	- [https://en.wikipedia.org/wiki/Radix_tree](https://en.wikipedia.org/wiki/Radix_tree)
	- [https://en.wikipedia.org/wiki/Trie](https://en.wikipedia.org/wiki/Trie)

- Markov chains:
	- [https://brilliant.org/wiki/markov-chains/](https://brilliant.org/wiki/markov-chains/)
	- [https://towardsdatascience.com/markov-and-hidden-markov-model-3eec42298d75]( https://towardsdatascience.com/markov-and-hidden-markov-model-3eec42298d75)
	- [https://en.wikipedia.org/wiki/Hidden_Markov_model]( https://en.wikipedia.org/wiki/Hidden_Markov_model)
	- [https://en.wikipedia.org/wiki/Markov_chain]( https://en.wikipedia.org/wiki/Markov_chain)

- Part of speech tagging:
	- [https://towardsdatascience.com/part-of-speech-tagging-for-beginners-3a0754b2ebba]( https://towardsdatascience.com/part-of-speech-tagging-for-beginners-3a0754b2ebba)
	- [https://en.wikipedia.org/wiki/Viterbi_algorithm]( https://en.wikipedia.org/wiki/Viterbi_algorithm)
